# (FusionFormerNet: An Audio-Visual Fusion Network Using DTC-FFNFormer for Time-Domain Speech Separation)
To demonstrate the effectiveness of our model on real-world audio visual speech data, we obtained several real-world video recordings from YouTube containing mixed speech from two speakers, to demonstrate the effectiveness of our separation model. The demo results can be accessed through the following link:

In this demo, the speakers in videos 1 and 2 are shown in frontal views, while the speakers in videos 3, 4, and 5 exhibit varying degrees of side faces or head movement:

[**The demo in Google cloud disk**]()

[**The demo in baidu cloud disk**]()
